{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN-Subsampling Algorithm\n",
    "\n",
    "The sampling algorithm is an iterative process based on Nearest Neighbour search. \n",
    "\n",
    "In each iteration, the dataset is normalized with the standard scaler (mean = 0, standard deviation = 1) and a nearest-neighbour model is constructed and queried to find the nearest neighbor for each data point as well as the distance between them. If the distance is below a certain cutoff distance, the neighbor is removed with some probability. The process is iterated until there are no more points to be removed. \n",
    "\n",
    "The algorithm has two hyper-parameters: cutoff distance and deletion probability (rate). \n",
    "\n",
    "The cutoff distance controls the sparsity of the resulting representative dataset. Higher cutoff distances resulting in fewer sub-sampled points.\n",
    "The deletion probability controls robustness. Lower deletion probablibity is more robust but resulting in slower execution. High deletion probablity might result in a \"hole\" in the subsampled dataset\n",
    "\n",
    "High-dimensional datasets may also be pre-processed by principal component analysis (PCA) to reduce the dimensionality prior to subsampling\n",
    "\n",
    "\n",
    "The illustration of the subsampling procedure is shown in the Figure below\n",
    "\n",
    "<center>\n",
    "    <img src=\"./subsample_schema.JPG\" width = 500>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Nearest-Neighbour search uses one of the packages below:\n",
    "\n",
    "* FLANN: http://www.cs.ubc.ca/research/flann/\n",
    "\n",
    "* pykdtree: https://github.com/storpipfugl/pykdtree\n",
    "\n",
    "* Annoy: https://github.com/spotify/annoy\n",
    "\n",
    "* nmslib: https://github.com/nmslib/nmslib/tree/master/python_bindings\n",
    "\n",
    "* scipy cKDTree\n",
    "\n",
    "* scikit-learn nearest neighbor\n",
    "\n",
    "Please make sure you have at least one of these packages installed before trying the algorithm (also remember to specify the method in your script)\n",
    "\n",
    "Also note that different packages may (sometimes very significantly) in speed, efficiency and result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (NNSubsampling.py, line 131)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3291\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-1-8ec51f063ea0>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from NNSubsampling import subsampling, subsampling_with_PCA, \\\n",
      "\u001b[0;36m  File \u001b[0;32m\"/usr/local/lib/python3.7/site-packages/NNSubsampling/__init__.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from .NNSubsampling import subsampling, subsampling_with_PCA, batch_subsampling, batch_subsampling_with_PCA, random_subsampling\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/usr/local/lib/python3.7/site-packages/NNSubsampling/NNSubsampling.py\"\u001b[0;36m, line \u001b[0;32m131\u001b[0m\n\u001b[0;31m    print(\"use nmslib backend\")\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "from NNSubsampling import subsampling, subsampling_with_PCA, \\\n",
    "                          batch_subsampling, batch_subsampling_with_PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Explanations of the Functions\n",
    "### Subsampling\n",
    "\n",
    "subsampling(data, list_desc = [], standard_scale = True, cutoff_sig = 0.05, rate = 0.3, method = \"pykdtree\", verbose = 1):\n",
    "    \n",
    "    Run the NN-based subsampling algorithm to a list of data points and \n",
    "    return the resulting list of subsampled data points\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    data: List. the original list of data points\n",
    "    \n",
    "    list_desc [[] (empty list)]:  List.\n",
    "                the indices of descriptors (features) of the datapoints. \n",
    "                The algorithm would subsample based only on these descriptors \n",
    "                (although other features will still be kept in the resulting subsampled dataset)\n",
    "                If the list is empty, then all feature will be taken into account\n",
    "    \n",
    "    standard_scale [True]: Boolean. Whether to apply standard scaler to the dataset prior to subsampling\n",
    "    \n",
    "    cutoff_sig [0.02]: Float. cutoff significance. the cutoff distance equals to the Euclidean \n",
    "                       norm of the standard deviations in all dimensions of the data points \n",
    "    \n",
    "    rate [0.3]: Float. possibility of deletion\n",
    "    \n",
    "    method [\"pykdtree\"]: String. which backend nearest neighbour model to use. \n",
    "                         possible choices: [\"pykdtree\", \"nmslib\", \"sklearn\", \"scipy\", \"annoy\", \"flann\"]\n",
    "    \n",
    "    verbose [1]: integer. level of verbosity\n",
    "    \n",
    "    \n",
    "    Return\n",
    "    -------------\n",
    "    sampling_result : the result list of subsampled data points\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subsampling_with_PCA\n",
    "subsampling_with_PCA(data, list_desc = [], standard_scale = True, cutoff_sig = 0.05, rate = 0.3, \n",
    "                                start_trial_component = 10, max_component = 30, target_variance = 0.999999, \n",
    "                                method = \"pykdtree\", verbose = 1):\n",
    "    \n",
    "    Run the NN-based subsampling algorithm to a list of data points and \n",
    "    return the resulting list of subsampled data points\n",
    "    \n",
    "    The data set will first be transformed by PCA, before running the subsampling algorithm\n",
    "    The number of PCs kept is the minimal number of PCs that have sum explained variance \n",
    "    greater than target_variance \n",
    "    \n",
    "    Note that the final resulting list of datapoints (sampling_result) is NOT transformed\n",
    "    (since we only used the PCA + subsampling alghorithm to find the indices of the datapoints to be kept)\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    data: List. the original list of data points\n",
    "   \n",
    "    list_desc [[] (empty list)]:  List.\n",
    "                the indices of descriptors (features) of the datapoints. \n",
    "                The algorithm would subsample based only on these descriptors \n",
    "                (although other features will still be kept in the resulting subsampled dataset)\n",
    "                If the list is empty, then all feature will be taken into account\n",
    "    \n",
    "    standard_scale [True]: Boolean. Whether to apply standard scaler to the dataset prior to subsampling\n",
    "    \n",
    "    cutoff_sig [0.02]: Float. cutoff significance. the cutoff distance equals to the Euclidean \n",
    "                       norm of the standard deviations in all dimensions of the data points \n",
    "    \n",
    "    rate [0.3]: Float. possibility of deletion\n",
    "    \n",
    "    start_trial_component [10]: Int. minimum number of PCs.\n",
    "                           if the number of features is below this number, then all features will be kept\n",
    "    \n",
    "    max_component [30]: Int.the maximum number of PCs to be kept, \n",
    "                        even the target variance has not been reached\n",
    "    \n",
    "    target_variance [0.999999]: Float. the target sum of variance. \n",
    "    \n",
    "    method [\"pykdtree\"]: String. which backend nearest neighbour model to use. \n",
    "                         possible choices: [\"pykdtree\", \"nmslib\", \"sklearn\", \"scipy\", \"annoy\", \"flann\"]\n",
    "    \n",
    "    verbose [1]: integer. level of verbosity\n",
    "    \n",
    "    \n",
    "    Return\n",
    "    -------------\n",
    "    sampling_result : the result list of subsampled data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch_subsampling\n",
    "batch_subsampling(data, list_desc = [], batch_size = 1000000, recursive_level = 1, \n",
    "                             standard_scale = True, cutoff_sig = 0.05, rate = 0.3, method = \"pykdtree\", \n",
    "                             verbose = 1, shuffle = True):\n",
    "\n",
    "    Subsample with batch\n",
    "    This is to save the memory if the data set of interest is too large.\n",
    "    \n",
    "    The data set will first be broken down into equally sized batchs (defined by batch size)\n",
    "    that will be subsampled individually.\n",
    "    The resulting subsampled datapoints will then be pooled together for a overall subsample\n",
    "    \n",
    "    In case this is not sufficient, multi-level batch subsampling is also allowed.\n",
    "    So instead of a overall subsample after pooling the resulting subsampled datapoints,\n",
    "    the pooled data points will again be broken down into batches for a second-level batch subsample.\n",
    "    This process is repeated multiple times (as defined by recursive_level) before eventually an \n",
    "    overall subsample is performed\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    data: List. the original list of data points\n",
    "    \n",
    "    list_desc [[] (empty list)]:  List.\n",
    "                the indices of descriptors (features) of the datapoints. \n",
    "                The algorithm would subsample based only on these descriptors \n",
    "                (although other features will still be kept in the resulting subsampled dataset)\n",
    "                If the list is empty, then all feature will be taken into account\n",
    "                \n",
    "    batch_size [1000000]: Int. the number of datapoints in each batch\n",
    "    \n",
    "    recursive_level [1]: Int. the number of levels for batch subsampling (as described above)\n",
    "\n",
    "    standard_scale [True]: Boolean. Whether to apply standard scaler to the dataset prior to subsampling\n",
    "    \n",
    "    cutoff_sig [0.02]: Float. cutoff significance. the cutoff distance equals to the Euclidean \n",
    "                       norm of the standard deviations in all dimensions of the data points \n",
    "    \n",
    "    rate [0.3]: Float. possibility of deletion\n",
    "    \n",
    "    method [\"pykdtree\"]: String. which backend nearest neighbour model to use. \n",
    "                         possible choices: [\"pykdtree\", \"nmslib\", \"sklearn\", \"scipy\", \"annoy\", \"flann\"]\n",
    "    \n",
    "    verbose [1]: integer. level of verbosity\n",
    "    \n",
    "    shuffle [True]: Boolean. whether to shuffle the dataset before breaking down into batchs\n",
    "    \n",
    "    \n",
    "    Return\n",
    "    -------------\n",
    "    sampling_result : the result list of subsampled data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch_subsampling_with_PCA\n",
    "\n",
    "batch_subsampling_with_PCA(data, list_desc = [], batch_size = 1000000, recursive_level = 1, \n",
    "                             start_trial_component = 10, max_component = 30, target_variance = 0.999999, \n",
    "                             standard_scale = True, cutoff_sig = 0.05, rate = 0.3, method = \"pykdtree\", \n",
    "                             verbose = 1, shuffle = True):\n",
    "    \n",
    "    '''\n",
    "    Subsample with batch (with PCA pre-processing)\n",
    "    This is to save the memory if the data set of interest is too large.\n",
    "    \n",
    "    The data set will first be broken down into equally sized batchs (defined by batch size)\n",
    "    that will be subsampled individually.\n",
    "    The resulting subsampled datapoints will then be pooled together for a overall subsample\n",
    "    \n",
    "    In case this is not sufficient, multi-level batch subsampling is also allowed.\n",
    "    So instead of a overall subsample after pooling the resulting subsampled datapoints,\n",
    "    the pooled data points will again be broken down into batches for a second-level batch subsample.\n",
    "    This process is repeated multiple times (as defined by recursive_level) before eventually an \n",
    "    overall subsample is performed\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    data: List. the original list of data points\n",
    "    \n",
    "    list_desc [[] (empty list)]:  List.\n",
    "                the indices of descriptors (features) of the datapoints. \n",
    "                The algorithm would subsample based only on these descriptors \n",
    "                (although other features will still be kept in the resulting subsampled dataset)\n",
    "                If the list is empty, then all feature will be taken into account\n",
    "                \n",
    "    batch_size [1000000]: Int. the number of datapoints in each batch\n",
    "    \n",
    "    recursive_level [1]: Int. the number of levels for batch subsampling (as described above)\n",
    "\n",
    "    standard_scale [True]: Boolean. Whether to apply standard scaler to the dataset prior to subsampling\n",
    "    \n",
    "    cutoff_sig [0.02]: Float. cutoff significance. the cutoff distance equals to the Euclidean \n",
    "                       norm of the standard deviations in all dimensions of the data points \n",
    "    \n",
    "    rate [0.3]: Float. possibility of deletion\n",
    "    \n",
    "    start_trial_component [10]: Int. minimum number of PCs.\n",
    "                           if the number of features is below this number, then all features will be kept\n",
    "    \n",
    "    max_component [30]: Int.the maximum number of PCs to be kept, \n",
    "                        even the target variance has not been reached\n",
    "    \n",
    "    target_variance [0.999999]: Float. the target sum of variance. \n",
    "    \n",
    "    method [\"pykdtree\"]: String. which backend nearest neighbour model to use. \n",
    "                         possible choices: [\"pykdtree\", \"nmslib\", \"sklearn\", \"scipy\", \"annoy\", \"flann\"]\n",
    "    \n",
    "    verbose [1]: integer. level of verbosity\n",
    "    \n",
    "    shuffle [True]: Boolean. whether to shuffle the dataset before breaking down into batchs\n",
    "    \n",
    "    \n",
    "    Return\n",
    "    -------------\n",
    "    sampling_result : the result list of subsampled data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial and Tests\n",
    "\n",
    "### prepare plot function and dataset\n",
    "\n",
    "Multi-dimensional normal distributed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "def plot(data):\n",
    "    \n",
    "    x_subsampled = data[:,0]\n",
    "    y_subsampled = data[:,1]\n",
    "\n",
    "    dataframe = pd.DataFrame({'x':x_subsampled, 'y':y_subsampled, 'group':np.repeat('subsampled',len(x_subsampled))})\n",
    "    sns.set(font_scale = 2)\n",
    "    with sns.axes_style('white'):\n",
    "        g = sns.JointGrid(x=\"x\", y=\"y\",data=dataframe,space=0)\n",
    "        g = g.plot_joint(plt.scatter, color = \"b\", s=30)\n",
    "\n",
    "        g.set_axis_labels(fontsize=50)\n",
    "\n",
    "        count = lambda a, b: len(a)\n",
    "        g.annotate(count, template=\"{val:.0f}\",stat=\"Count\",loc=\"upper right\", fontsize = 20)\n",
    "\n",
    "        _ = g.ax_marg_x.hist(dataframe[\"x\"], color = \"b\", alpha = 0.6, bins = np.arange(-0.5, 0.5, 0.02))\n",
    "        _ = g.ax_marg_y.hist(dataframe[\"y\"], color = \"b\", alpha = 0.6, orientation = \"horizontal\",bins = np.arange(0, 200, 4))\n",
    "        plt.show()\n",
    "    return\n",
    "\n",
    "n = 1000000\n",
    "x1_mu, x1_sigma = 0, 0.1\n",
    "x2_mu, x2_sigma = 100, 20\n",
    "x3_mu, x3_sigma = 15, 40\n",
    "x4_mu, x4_sigma = -20, 5\n",
    "x5_mu, x5_sigma = 1000, 0.1\n",
    "x6_mu, x7_sigma = 0.0, 30\n",
    "x7_mu, x6_sigma = 12, 2\n",
    "x8_mu, x8_sigma = 50, 40\n",
    "x9_mu, x9_sigma = 5, 20\n",
    "x10_mu, x10_sigma = 10, 2\n",
    "\n",
    "\n",
    "x1 = np.random.normal(x1_mu, x1_sigma, n)\n",
    "x2 = np.random.normal(x2_mu, x2_sigma, n)\n",
    "x3 = np.random.normal(x3_mu, x3_sigma, n)\n",
    "x4 = np.random.normal(x4_mu, x4_sigma, n)\n",
    "x5 = np.random.normal(x5_mu, x5_sigma, n)\n",
    "x6 = np.random.normal(x6_mu, x6_sigma, n)\n",
    "x7 = np.random.normal(x7_mu, x7_sigma, n)\n",
    "x8 = np.random.normal(x8_mu, x8_sigma, n)\n",
    "x9 = np.random.normal(x9_mu, x9_sigma, n)\n",
    "x10 = np.random.normal(x10_mu, x10_sigma, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorials\n",
    "\n",
    "1,000,000 Multi-dimensional normally distributed data points.\n",
    "\n",
    "we will only use the \"pykdtree\" backend in the tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial 1: 2D toy case, with different rate and cutoff_sig\n",
    "\n",
    "1. higher rate --> fewer iterations, faster execution, but less nicely distributed results\n",
    "2. higher cutoff_sig --> more sparse resulting subsampled datapoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/seaborn/axisgrid.py:1847: UserWarning: JointGrid annotation is deprecated and will be removed in a future release.\n",
      "  warnings.warn(UserWarning(msg))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_2D = np.column_stack((x1,x2))\n",
    "plot(data_2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### subsample with cutoff_sig = 0.05, rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subsampling' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-51a2e3224bb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubsampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcutoff_sig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"pykdtree\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'subsampling' is not defined"
     ]
    }
   ],
   "source": [
    "subsampled = np.asarray(subsampling(data_2D,list_desc = [],cutoff_sig=0.1,rate=0.2, method = \"pykdtree\",verbose = 2))\n",
    "\n",
    "plot(subsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### subsample with cutoff_sig = 0.1, rate = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subsampled = np.asarray(subsampling(data_2D,list_desc = [],cutoff_sig=0.1,rate=0.6, method = \"pykdtree\",verbose = 2))\n",
    "\n",
    "plot(subsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### subsample with cutoff_sig = 0.4, rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subsampled = np.asarray(subsampling(data_2D,list_desc = [],cutoff_sig=0.4,rate=0.2, method = \"pykdtree\",verbose = 2))\n",
    "\n",
    "plot(subsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial 2: Subsample based on subset of features\n",
    "\n",
    "In this case subsample based on feature 1 of the 2D dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampled = np.asarray(subsampling(data_2D,list_desc = [0],cutoff_sig=0.1,rate=0.2, method = \"pykdtree\",verbose = 1))\n",
    "\n",
    "plot(subsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial 3: Subsample with PCA-preprocessing for high-dimensional dataset\n",
    "\n",
    "we will demostrate with a 10-D dataset\n",
    "\n",
    "PCA is first done on the dataset, and first N PCs that captured 99% variance of the \n",
    "original dataset are used to subsample the dataset\n",
    "\n",
    "Note although the dataset is subsampled with PCs, the resulting subsampled dataset is\n",
    "not PCA transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.column_stack((x1,x2,x3,x4,x5,x6,x7,x8,x9,x10))\n",
    "\n",
    "print(\"original dataset shape: {}\".format(temp.shpae))\n",
    "\n",
    "subsampled = subsampling_with_PCA(temp,list_desc = [], start_trial_component = 5, max_component = 10, \\\n",
    "                                  target_variance = 0.99, cutoff_sig=1.0,rate=0.2, \\\n",
    "                                  method = \"pykdtree\",verbose = 1)\n",
    "\n",
    "print(\"result dataset shape: {}\".format(np.array(subsampled).shpae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial 4: Batch subsample with for large dataset\n",
    "\n",
    "Batch subsampling with 100,000 and 10,000 batch sizes were tested. 2 observations could be made:\n",
    "\n",
    "1. subsampling based on small batchs sucessfully lowered the cost of the subsampling algorithm\n",
    "2. seems the resulting sabsampled datasets are much more sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 100,000 datapoints in a batch, with 2 levels of batch subsample\n",
    "subsample with cutoff_sig = 0.1, rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "subsampled = np.array(batch_subsampling(data_2D,list_desc = [], batch_size = 100000, recursive_level = 1, \\\n",
    "                                                      cutoff_sig=0.1,rate=0.2, method = \"pykdtree\",verbose = 1))\n",
    "\n",
    "print(\"total time: {}\".format(time.time()-start))\n",
    "\n",
    "plot(subsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10,000 datapoints in a batch, with 2 levels of batch subsample\n",
    "subsample with cutoff_sig = 0.1, rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "temp_subsampled = np.array(batch_subsampling(data_2D,list_desc = [], batch_size = 10000, recursive_level = 2, \\\n",
    "                                                      cutoff_sig=0.1,rate=0.2, method = \"pykdtree\",verbose = 1))\n",
    "\n",
    "print(\"total time: {}\".format(time.time()-start))\n",
    "\n",
    "plot(subsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: scaling in multiple dimensions with different backend\n",
    "\n",
    "2 different backends were tested\n",
    "\n",
    "1. pykdtree backend seems to be very efficient for lower dimension dataset, but scales badly with number of dimensions\n",
    "\n",
    "2. nmslib backed performed much worse for lower dimension datasets, but scales better with dimension\n",
    "\n",
    "#### pykdtree backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.column_stack((x1,x2))\n",
    "start = time.time()\n",
    "subsampling(temp,list_desc = [], cutoff_sig=1.0,rate=0.2, method = \"pykdtree\",verbose = False)\n",
    "\n",
    "print(\"2 dimensions, total time: {}\\n\\n\".format(time.time()-start))\n",
    "\n",
    "temp = np.column_stack((x1,x2,x3,x4,x5))\n",
    "start = time.time()\n",
    "subsampling(temp,list_desc = [], cutoff_sig=1.0,rate=0.2, method = \"pykdtree\",verbose = False)\n",
    "\n",
    "print(\"5 dimensions,total time: {}\\n\\n\".format(time.time()-start))\n",
    "\n",
    "temp = np.column_stack((x1,x2,x3,x4,x5,x6,x7,x8,x9,x10))\n",
    "start = time.time()\n",
    "subsampling(temp,list_desc = [], cutoff_sig=1.0,rate=0.2, method = \"pykdtree\",verbose = False)\n",
    "\n",
    "print(\"10 dimensions total time: {}\\n\\n\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nmslib backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp = np.column_stack((x1,x2))\n",
    "start = time.time()\n",
    "subsampling(temp,list_desc = [], cutoff_sig=1.0,rate=0.2, method = \"nmslib\",verbose = False)\n",
    "\n",
    "print(\"2 dimensions, total time: {}\\n\\n\".format(time.time()-start))\n",
    "\n",
    "temp = np.column_stack((x1,x2,x3,x4,x5))\n",
    "start = time.time()\n",
    "subsampling(temp,list_desc = [], cutoff_sig=1.0,rate=0.2, method = \"nmslib\",verbose = False)\n",
    "\n",
    "print(\"5 dimensions,total time: {}\\n\\n\".format(time.time()-start))\n",
    "\n",
    "temp = np.column_stack((x1,x2,x3,x4,x5,x6,x7,x8,x9,x10))\n",
    "start = time.time()\n",
    "subsampling(temp,list_desc = [], cutoff_sig=1.0,rate=0.2, method = \"nmslib\",verbose = False)\n",
    "\n",
    "print(\"10 dimensions total time: {}\\n\\n\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: MNIST dataset test\n",
    "\n",
    "subsampling with PCA pre-processing and different backends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.data import loadlocal_mnist\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "X, y = loadlocal_mnist(\n",
    "        images_path='./train-images-idx3-ubyte', \n",
    "        labels_path='./train-labels-idx1-ubyte')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = subsampling_with_PCA(X,list_desc = [],standard_scale = False, max_component = 120, target_variance = 0.98,\\\n",
    "                                     cutoff_sig=1.5,rate=0.1, method = \"nmslib\", verbose = 1)\n",
    "for image in result:\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(image.reshape(28,28))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = subsampling_with_PCA(X,list_desc = [],standard_scale = False, max_component = 120, target_variance = 0.98,\\\n",
    "                                     cutoff_sig=1.5,rate=0.1, method = \"pykdtree\", verbose = 1)\n",
    "for image in result:\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(image.reshape(28,28))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = subsampling_with_PCA(X,list_desc = [],standard_scale = False, max_component = 120, target_variance = 0.98,\\\n",
    "                                     cutoff_sig=1.5,rate=0.1, method = \"annoy\", verbose = 1)\n",
    "for image in result:\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(image.reshape(28,28))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: fashion-MNIST dataset test\n",
    "\n",
    "subsampling with PCA pre-processing and different backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = loadlocal_mnist(\n",
    "        images_path='./train-fasion-images-idx3-ubyte', \n",
    "        labels_path='./train-fasion-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = subsampling_with_PCA(X,list_desc = [],standard_scale = False, max_component = 120, target_variance = 0.98,\\\n",
    "                                     cutoff_sig=1.5,rate=0.1, method = \"nmslib\", verbose = 1)\n",
    "for image in result:\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(image.reshape(28,28))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = subsampling_with_PCA(X,list_desc = [],standard_scale = False, max_component = 120, target_variance = 0.98,\\\n",
    "                                     cutoff_sig=1.5,rate=0.1, method = \"pykdtree\", verbose = 1)\n",
    "for image in result:\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(image.reshape(28,28))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = subsampling_with_PCA(X,list_desc = [],standard_scale = False, max_component = 120, target_variance = 0.98,\\\n",
    "                                     cutoff_sig=1.5,rate=0.1, method = \"annoy\", verbose = 1)\n",
    "for image in result:\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(image.reshape(28,28))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
